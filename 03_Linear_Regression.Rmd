---
title: "03_Linear Regression"
author: "Lian Rui"
date: "2024-07-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = F,
                      warning = F)
```

```{r}
library(tidyverse)
```

## Simple Linear Regression

Assume a linear relationship: 

$$
Y = \beta_0 + \beta_1X + \epsilon \approx \beta_0 + \beta_1X
$$

Estimate the linear relationship: 

$$
\hat{y} = \hat{\beta}_{0} + \hat{\beta_1}x
$$

### 3.1.1 Estimating the Coefficients

Residual sum of squares (RSS)

$$
\begin{align}
\text{RSS} &= e_1^2 + e_2^2 + \cdots + e_n^{2} \\
&= (y_1 - \hat{\beta}_0^2 - \hat{\beta}_1x_1)^2 + (y_2 - \hat{\beta}_0 - \hat{\beta}_2x_2)^2 + \cdots + (y_1 - \hat{\beta}_0^2 - \hat{\beta}_nx_n)^2
\end{align}
$$

### 3.1.2 Assessing the Accuracy of the Coefficient Estimates

__Simulation of fig 3.3 to show population line and least square line__

Summary: 
Population regression line, least squares line, bias, unbiased, standard error of estimate, Residual standard error, confident interval hypothesis test, null hypothesis, alternative hypothesis, t-statistic. 

__Background:__ 
Model assumptions and factors that lead to linear regression model unreliable 

-. Linearity: linear relationship between outcome and predictors. 

-. Independence: no collinearity among predictors. 

-. Homoscedasticity: variance of residuals is constant. 

-. Normal Residuals: residuals are normal distributed. 

  - Residual plot to check linearity, homoscedasticity and identify outliers
  
  - Histograms or QQ plot of residuals to check normality
  
  - Variance Inflation Factor (VIF) to check multicollinearity
  
  - Durbin-Watson test for check for autocorrelation. 

-. No Autocorrelations: 

-. Sample size: 

-. No outliers. 

-. Model is appropriately specified. 

Population line is theoretical, and we always get the least square line. 

Standard error of the estimates of linear regression: 

__Standard Errors of Estimates__

Standard error of $\hat{\beta_0}$: 

$$
\text{SE}(\hat{\beta}_0) = \sqrt{\sigma^2 \left( \frac{1}{n} + \frac{\bar{X}^2}{\sum_{i=1}^{n} (X_i - \bar{X})^2} \right)}
$$

Standard error of $\hat{\beta_1}$:

$$
\text{SE}(\hat{\beta}_1) = \sqrt{\frac{\sigma^2}{\sum_{i=1}^{n} (X_i - \bar{X})^2}}

$$

all the uncertainties or unreliability of estimates are in sigma square. And sigma square may have something not random is the assumption is violated. 

__Hypothesis Testing__

$H_0$: There is no relationship between X and Y, $H_0: \beta_1 = 0$

$H_a$: There is some relationship between X and Y, $H_1: \beta1 \neq 0$

t-statistic: 

$$
t = \frac{\hat{\beta_1} - 0}{\text{SE}(\hat{\beta_1})}
$$

### 3.1.3 Assessing the Accuracy of the Model

__Three Metrics__: 

RSE: average size of residuals, how well the model fit the data in absolute values. 

$$
\text{RSE} = \sqrt{\frac{1}{n-2}\text{RSS}} = \sqrt{\frac{1}{n-2}\sum_{i = 1}^{n}(y_i -\hat{y_i}^2)}
$$

$R^2$: The proportion of the variance in the outcome variable that is explained by the model, goodness of fit. 

$$
\text{TSS} = \sum(y_i - \bar{y})^2
$$

$$
R^2 = \frac{\text{TSS} - \text{RSS}}{TSS}
$$

F-statistic: Overall significance of the model, whether the predictors, as a group, contribute significantly to explain the outcome variable. 

$$
\begin{align}
F &= \frac{(\text{TSS}- \text{RSS})/p}{\text{RSS}/(n - p -1)} \\
&= \frac{\text{MS}_\text{reg}}{\text{MS}_\text{rss}}
\end{align}
$$

__Three Metrics__ may have discrepancies. 

Yes, it's possible for the Residual Standard Error (RSE), R-squared (\(R^2\)), and F-statistic to present different or even conflicting indications about a linear regression model's performance. Here's how these metrics can sometimes go in different directions:

### 1. **RSE and \(R^2\)**

- **RSE and \(R^2\) Relationship**:
  - Generally, \(R^2\) and RSE are inversely related. A higher \(R^2\) indicates that a larger proportion of the variance is explained by the model, which typically results in a lower RSE, as the residuals are smaller on average.
  - However, this is not always straightforward. Adding more predictors to a model can increase \(R^2\) (even if the predictors are not truly informative), while RSE might not decrease significantly or could even increase if the additional predictors do not genuinely improve the model.

- **Possible Discrepancies**:
  - **High \(R^2\) with High RSE**: If \(R^2\) is high but RSE is still large, it could mean that the model explains a good portion of variance, but there is still a lot of variability in the residuals, possibly due to outliers or variability not captured by the model.
  - **Low \(R^2\) with Low RSE**: If \(R^2\) is low but RSE is low as well, the model might fit the data well in an absolute sense but fail to capture a meaningful relationship between the predictors and the response.

### 2. **F-statistic**

- **F-statistic Role**:
  - The F-statistic tests the null hypothesis that all regression coefficients are zero (i.e., that the model has no explanatory power). A high F-statistic indicates that the predictors collectively have a significant effect on the response variable.

- **Possible Discrepancies**:
  - **High F-statistic with Low \(R^2\**: If the F-statistic is high but \(R^2\) is low, it could suggest that the model as a whole is statistically significant, but the proportion of explained variance is still relatively small. This might happen if the model improves the fit significantly compared to a baseline model, but the overall fit is still poor.
  - **Low F-statistic with High \(R^2\)**: If the F-statistic is low while \(R^2\) is high, this might be unusual, but it could occur in cases where the degrees of freedom or sample size are very small. The F-statistic might not be large enough to reach statistical significance, even if the model explains a lot of variance.

### 3. **Conflicting Metrics Scenario**

In practice, the metrics can sometimes provide conflicting indications:
- **Adding Predictors**: Adding more predictors usually increases \(R^2\) and might decrease RSE if the predictors are useful. However, if the additional predictors are irrelevant, \(R^2\) may be inflated and RSE might not decrease, leading to a misleading impression of model quality.
- **Model Overfitting**: A model with many predictors might show high \(R^2\) and low RSE on the training data but perform poorly on new data (high variance), which may not be apparent from these metrics alone.

### Summary

- **RSE** provides a direct measure of the average size of residuals and reflects how well the model fits the data in absolute terms.
- **\(R^2\)** indicates the proportion of the variance in the response variable that is explained by the model and is often used to assess the goodness of fit.
- **F-statistic** evaluates the overall significance of the model, testing whether the predictors, as a group, contribute significantly to explaining the response variable.

When interpreting these metrics, it's important to consider the context and potential limitations. For example, **\(R^2\)** alone may be misleading if used without considering the number of predictors or the potential for overfitting. The **F-statistic** helps assess model significance, but its value should be interpreted alongside other metrics and diagnostic tests to get a comprehensive understanding of model performance.

## Multiple Linear Regression

### 3.2.1 Estimating the Regression Coefficients

### 3.2.2 Some Important Questions

__Model fit, and relationship of predictor and response__
Is there a relationship between the response and predictors? 

1. Start with the F-statistic: 

If the overall model is significant (large F-statistic with a small p-value), this suggests that the predictors collectively have a significant relationship with the response.

2. Check R-squared: 

A high $R^2$ indicates that the model explains a substantial proportion of the variance in the response variable.

3. Review RSE: 

A low RSE indicates that the modelâ€™s predictions are close to the actual values.

4. Look at Individual t-statistics: 

Identify which predictors are significantly contributing to the model by checking the t-statistics and associated p-values. Predictors with significant t-statistics (small p-values) have a significant relationship with the response variable.

__Important Variables__

Individual t-statistics of variables. 



## Other Considerations in the Regression Model

## The Marketing Plan

## Comparison of Linear Regression with K-Nearest Neighbors

## Linear Regression for Later Machine Learning

Linear regression is classic, what are the learnings from linear regression that can be jump-off points that are helpful to late state-of-art machine learning approaches

- Model Interpretability

- Regularization

- Assumpution and assumption testing tools

- Model specification and feature engineering

- Model evaluation: accuracy, F1-Score, AUC_ROC

- Cross-validation

- Bias-Variance tradeoff


## Concepts Summary

## Lab: Linear Regression

## Exercises. 